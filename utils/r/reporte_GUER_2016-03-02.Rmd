---
title: "Reporte SMCP"
output: html_document
params:
  estado: !r as.character(estado)
---

```{r,echo=FALSE,message=FALSE,warning=FALSE}
library(tm.plugin.webmining)
library(XML)
library(tm)
library(tidyr)
library(dplyr)
library(RPostgreSQL)
library(RMySQL)
library(lubridate)
library(stringr)
library(RCurl)
library(knitr)
library(irlba)
library(Matrix)
library(tm)
library(ggplot2)
library(ggmap)
library(mapproj)
library(gridExtra)
library(png)
library(grid)
library(RTextTools)
library(ggthemes)
library(slam)
library(reshape2)
library(plotly)
library(textcat)
```

#Análisis del estado __`r estado`__ 
La información a continuación se generó de la fecha __`r Sys.Date()-7`__ a la fecha __`r Sys.Date()`__


###Ranking 

```{r,echo=FALSE,message=FALSE,warning=FALSE}
#source("/Users/lechuga/Dropbox/smcp (1)/Lechuga_smpc/desarrollo_indicadoresDashboard/generacion_reporte/get_rank.r")
#Me necesito conectar con la tabla "tb4"
source("/home/ubuntu/dashboard/reportes/utils_reporte/utils_reporteGral.r")
rank <- getG_rank(estado)
```


El estado __`r estado`__ se encuentra en la posición `r rank` del ranking general.




```{r,echo=FALSE,message=FALSE,warning=FALSE,eval=FALSE}


cor_data <- tryCatch({get_correlation_week()
               },
      error = function(e){cat("ERROR :",conditionMessage(e), "\n")}
    )


### Correlación objetiva vs subjetiva

#En general la correlación entre los indicadores de percepción en redes sociales (_subjetivos_) vs los indicadores de percepción de las noticas (_objetivos_) está dada por la siguiente tabla:

#`r kable(cor_data)`
```

###Noticias más relevantes 

```{r,echo=FALSE,message=FALSE,warning=FALSE}
## SECCIÓN DE NOTICIAS

lista_termino <- paste(estado,'México')

corpus_noticias_mex <- lapply(lista_termino, function(i) WebCorpus(GoogleNewsSource(params=list(hl = "spanish", q = i, ie ="utf-8", num = 40, gl = "MX", output = "rss"))))

#funcion para filtrar elementos
make_row <- function(elem) {
    data.frame(timestamp=elem[[2]]$datetimestamp,
               heading=elem[[2]]$heading,
               description=elem[[2]]$description,
               origin=elem[[2]]$origin,
               stringsAsFactors=FALSE)
}


#en un for para hacer un data frame de las noticias
agregado <- cbind(bind_rows(lapply(corpus_noticias_mex[[1]], make_row)),estado = estado)

agregado <- agregado %>%
    separate(heading, into = c("heading", "newspaper"), sep = " - ") %>%
    separate(timestamp, into = c("date_created", "shiza"), sep = " ") %>%
    select(date_created,heading,newspaper,description,origin,estado)

agregado <- agregado %>%
    mutate(lang = lapply(agregado$heading, textcat)) %>%
    filter(lang != "scots", lang != "english") %>%
    select(-lang) %>%
    head(10)

kable(select(agregado, date_created, heading, newspaper, description))


```


###Términos

A continuación se muestran los términos más importantes generados en el cuerpo de las noticias.

```{r,echo=FALSE,message=FALSE,warning=FALSE}

corp.com <- Corpus(VectorSource(agregado$description), readerControl = list(language ='spa'))
corp.com.1 <- tm_map(corp.com, stripWhitespace)
corp.com.2 <- tm_map(corp.com.1, tolower)
corp.com.3 <- tm_map(corp.com.2,  function(x){
  gsub('[-«»\\\',;:".!¡¿?\\(\\)]','',x)
}) 
mis_stops <- as.character(read.table("/home/ubuntu/dashboard/reportes/utils_reporte/espanol_stops.txt")[,1])
corp.com.4 <- tm_map(corp.com.3, removeWords, mis_stops)
corp.com.4 <- tm_map(corp.com.4, stripWhitespace)
corp.4 <- tm_map(corp.com.4, function(x){
  z <- strsplit(x, " +")[[1]]
  #z.stem <- wordStem(z, language="spanish")
  PlainTextDocument(paste(z, collapse=" "))
})
#hacemos la matriz de terminos documentos
dtm <- TermDocumentMatrix(corp.4,
                          control = list(bounds=list(global=c(1,Inf)), 
                                         stopwords=FALSE,
                                         weighting = function(x){ 
                                           weightTfIdf(x, normalize = FALSE)
                                         }))
#terminos frecuentes
freq.terms <- findFreqTerms(dtm, lowfreq = 5)
term.freq <- rowSums(as.matrix(dtm))
term.freq <- subset(term.freq, term.freq >= 5)
df <- data.frame(term = names(term.freq), freq = term.freq)
#top 20 
df_20 <- head(arrange(df, desc(freq)),20)

#aplicar la funcion de asociación de términos a los 20 más frecuentes
relation_terms <- apply(df_20, 2, function(x) findAssocs(dtm, x, 0.25))

#Pasarlo a una estructura en la que pueda visualizarlo como red
term_assocs <- melt(relation_terms$term[1])
colnames(term_assocs) <- c("asociacion", "categoria")
term_assocs$termino <- row.names(term_assocs)
rownames(term_assocs) <- NULL

for(i in 2:length(relation_terms$term)){
  sup <- melt(relation_terms$term[i])
  colnames(sup) <- c("asociacion", "categoria")
  sup$termino <- row.names(sup)
  rownames(sup) <- NULL
  term_assocs <- rbind(term_assocs, sup)
}

kable(df_20)

ggplot(df_20, aes(x = reorder(term, freq), y = freq))  +
  geom_bar(stat = "identity", fill = "darkgray") +
  #theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  geom_hline(aes(yintercept=mean(df_20$freq)), color='red') +
  labs(x="Término",y="Frecuencia") + ggtitle('Términos más frecuentes') + coord_flip()

#gráfica con los valores agrupados por concepto y asociados por fuerza
#term_assocs
#a <- filter(term_assocs,asociacion > 0.35)
#plot_ly(a, x = termino, y = asociacion, text = paste("Categoría: ", categoria),
#        mode = "markers", size = asociacion)

```


###Desempeño del indicador 

A continuación se muestra el desempeño del indicador correspondendientes al estado __`r estado`__ 


```{r,echo=FALSE,message=FALSE,warning=FALSE}
#cargamos la función para obtener el desempeño
#source("/Users/lechuga/Dropbox/smcp (1)/Lechuga_smpc/desarrollo_indicadoresDashboard/generacion_reporte/get_performance.r")

performance <- getG_indicadorPerformance(estado)

kable(performance)

performancePlot <- ggplot(performance, aes(x=date_created, y=score)) + geom_line()

plot_ly(performancePlot)
```


A continuación se muestran los términos más importantes generados en el cuerpo de las tweets referente al estado __`r estado`__ 

```{r,echo=FALSE,message=FALSE,warning=FALSE}
#source("/Users/lechuga/Dropbox/smcp (1)/Lechuga_smpc/desarrollo_indicadoresDashboard/generacion_reporte/get_topWordsTweets.r")


# df_20 <- tryCatch({getG_topWords(estado)},
#       error = function(e){cat("ERROR :",conditionMessage(e), "\n")} 
#     )

df_20 <- getG_topWords(estado)

#kable(df_20)
      
ggplot(df_20, aes(x = reorder(term, freq), y = freq))  +
  geom_bar(stat = "identity", fill = "darkgray") +
  #theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  geom_hline(aes(yintercept=mean(df_20$freq)), color='red') +
  labs(x="Término",y="Frecuencia") + ggtitle('Términos más frecuentes') + coord_flip()

```


Las zonas con más actividad son:

```{r,echo=FALSE,message=FALSE,warning=FALSE, fig.width=10,fig.height=8}
source("/home/ubuntu/dashboard/reportes/utils_reporte/get_Map.r")

mapa_data <- tryCatch({getG_Map(estado)
               },
      error = function(e){cat("ERROR :",conditionMessage(e), "\n")} 
    )

mapa_data <- mapa_data %>%
  filter(polarizacion != 'neutral')

lon_ref <- mapa_data[1,1]
lat_ref <- mapa_data[1,2]
map <- get_map(location = c(lon = lon_ref, lat = lat_ref), zoom = 11,
  scale = "auto")
map_2 <- ggmap(map) +
  geom_point(data = mapa_data, aes(x=lon, y=lat, colour = polarizacion, size = 3), alpha
= I(0.65)) + scale_color_manual(values = c("red", "green3")) + 
  facet_wrap(~ polarizacion, nrow = 1)
map_2

```


###Tabla de correlación correspondiente al estado `r estado`

```{r, echo=FALSE,message=FALSE,warning=FALSE,fig.width=10,fig.height=10}

cor_table <- get_corTable(estado)
cor_table

```















